# Pipeline de Donn√©es RTE (Data Lake & Monitoring)

Ce projet impl√©mente un pipeline de donn√©es complet : Ingestion (Airflow) -> Datalake (MongoDB) -> Traitement (Spark) -> Stockage Final (PostgreSQL) -> Monitoring (Grafana/pgAdmin).

## üöÄ D√©marrage Rapide

### Prerequis

1. Clone le projet
``git clone https://github.com/IMT-Ales/BigData``

1. Avoir le deamon docker de lanc√©

### D√©marrage

Pour lancer toute la stack :

```bash
docker compose up -d
```

Pour arr√™ter : `docker compose down`.

## üîÑ Fonctionnement du Pipeline

Ce projet orchestre un pipeline ELT (Extract, Load, Transform) complet pour analyser les donn√©es √©nerg√©tiques de RTE :

1.  **Ingestion (Airflow)** : Une DAG Airflow interroge l'API OpenData de RTE tous les jours.
2.  **Data Lake (MongoDB)** : Les donn√©es brutes (JSON) sont stock√©es dans MongoDB. Cela permet de conserver l'historique complet sans perte d'information.
3.  **Transformation (Spark)** : Un job Spark lit les donn√©es brutes de Mongo, les nettoie, les agr√®ge (par r√©gion et fili√®re), et calcule des m√©triques cl√©s.
4.  **Stockage Structur√© (PostgreSQL)** : Les donn√©es raffin√©es sont ins√©r√©es dans une table PostgreSQL optimis√©e pour l'analyse.
5.  **Visualisation (Grafana)** : Des dashboards connect√©s √† Postgres et Loki permettent de suivre les m√©triques m√©tiers (consommation, production) et techniques (logs, sant√© des bases).

## üöÄ Guide d'Utilisation

Une fois le `docker compose up -d` effectu√©, voici comment utiliser et v√©rifier le pipeline :

### 1. Activer le Pipeline (Airflow)
*   Acc√©dez √† l'interface Airflow : [http://localhost:8080](http://localhost:8080)
*   **Login/Mdp** : `airflow` / `airflow`
*   Sur la page d'accueil (DAGs), vous verrez les DAGs (ex: `rte_ingestion_dag`).
*   **Important** : Par d√©faut, les DAGs sont en "Pause". Cliquez sur le bouton toggle (ON/OFF) √† gauche du nom du DAG pour l'activer.
*   Le scheduler lancera automatiquement les t√¢ches selon la planification. Pour forcer une ex√©cution imm√©diate, cliquez sur le bouton "Play" √† droite de la ligne du DAG.

![Airflow Dashboard](imgs/airflow-dashboard.png)

![Airflow Graph](imgs/airflow.png)

### 2. V√©rifier les Donn√©es (Grafana & Postgres)

#### Via Grafana (Visualisation)
*   Acc√©dez √† Grafana : [http://localhost:3000](http://localhost:3000)
*   **Login/Mdp** : `admin` / `admin`
*   Allez dans le menu **Dashboards**. Vous y trouverez des tableaux de bord pr√©-configur√©s pour visualiser les donn√©es √©nerg√©tiques (graphiques de consommation, mix √©nerg√©tique) ainsi que le monitoring technique.

![Grafana Dashboard](imgs/postgres-dashboard.png)

#### Via PostgreSQL (Acc√®s Direct)
Pour v√©rifier que les donn√©es sont bien arriv√©es en base :
*   Connectez-vous √† la base de donn√©es (via pgAdmin ou CLI) :
    *   **Port** : `5433` (attention, c'est 5433 en local pour ne pas confict avec un postges local)
    *   **User/Mdp/DB** : `airflow` / `airflow` / `airflow` (ou `rte_data` selon config)
*   Ex√©cutez la requ√™te SQL suivante :  
    ```sql
    SELECT * FROM public.regional_energy_stats;
    ```
    Vous devriez voir les derni√®res donn√©es agr√©g√©es.

## üõ†Ô∏è Acc√®s aux Services Techniques

| Service | URL | Login | Mot de passe | Description |
| :--- | :--- | :--- | :--- | :--- |
| **Airflow** | `http://localhost:8080` | `airflow` | `airflow` | Orchestration. |
| **Grafana** | `http://localhost:3000` | `admin` | `admin` | Visualisation. |
| **Postgres** | `localhost:5433` | `airflow` | `airflow` | DB Finale. |
| **Mongo** | `localhost:27017` | `admin` | `password` | Data Lake. |

### Configuration pgAdmin
Si vous utilisez pgAdmin [http://localhost:5050](http://localhost:5050) :
*   **Host Name** : `postgres` (nom du service docker)
*   **Port** : `5432` (port interne docker)
*   **User** : `airflow`

## ‚úÖ Int√©gration Continue (CI)

Chaque modification du code (Push ou Pull Request sur `main`) d√©clenche automatiquement un pipeline GitHub Actions d√©fini dans `.github/workflows/ci.yml`.

Ce pipeline assure la qualit√© et la stabilit√© du projet via deux jobs principaux :

1.  **Python Checks (Qualit√© du Code)** :
    *   Installation des d√©pendances Python.
    *   Analyse statique du code avec **Flake8** pour v√©rifier le style et d√©tecter les erreurs de syntaxe.

2.  **Docker Build (Validit√© du Build)** :
    *   Tente de construire l'image Docker de l'application.
    *   Garantit que le `Dockerfile` est valide et que l'image peut √™tre g√©n√©r√©e sans erreur.

## üôç‚Äç‚ôÇÔ∏è Groupes

* Maxence Tourniayre (Xamez)
* Thomas Nalix 
* Rohart Yoann