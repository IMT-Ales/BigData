# Pipeline de DonnÃ©es RTE (Data Lake & Monitoring)

Ce projet implÃ©mente un pipeline de donnÃ©es complet : Ingestion (Airflow) -> Datalake (MongoDB) -> Traitement (Spark) -> Stockage Final (PostgreSQL) -> Monitoring (Grafana/pgAdmin).

## ğŸš€ DÃ©marrage Rapide

### Prerequis

1. Clone le projet
``git clone https://github.com/IMT-Ales/BigData``

1. Avoir le deamon docker de lancÃ©

### DÃ©marrage

Pour lancer toute la stack :

```bash
docker compose up -d
```

Pour arrÃªter : `docker compose down`.

## ğŸ› ï¸ AccÃ¨s aux Services

| Service | URL | Login | Mot de passe | Description |
| :--- | :--- | :--- | :--- | :--- |
| **Airflow** | `http://localhost:8080` | `airflow` | `airflow` | Orchestration des DAGs. |
| **Grafana** | `http://localhost:3000` | `admin` | `admin` | Visualisation des mÃ©triques & logs. |
| **pgAdmin** | `http://localhost:5050` | `admin@admin.com` | `root` | Interface web pour PostgreSQL. |
| **Postgres** | `localhost:5433` | `airflow` | `airflow` | Base de donnÃ©es finale (Port Docker). |
| **Mongo** | `localhost:27017` | `admin` | `password` | Data Lake brut. |

### Configuration pgAdmin (Ajout Serveur)
Une fois connectÃ© Ã  pgAdmin, ajoutez un nouveau serveur avec :
*   **Host API** : `postgres` (RÃ©seau Docker interne)
*   **Username** : `airflow`
*   **Password** : `airflow`
*   **Maintenance DB** : `airflow` (ou `rte_data`)

## ğŸ“Š DonnÃ©es & Traitement

### 1. Source (API RTE)
RÃ©cupÃ©ration des donnÃ©es **Ã©CO2mix rÃ©gionales temps rÃ©el** via l'API OpenDataSoft de RTE.
*   **DonnÃ©es** : Consommation, Echanges physiques, Production par filiÃ¨re.
*   **FrÃ©quence** : Ingestion quotidienne (`@daily`).

### 2. Pipeline de Traitement (Spark)
Un job PySpark est dÃ©clenchÃ© automatiquement aprÃ¨s l'ingestion.
*   **Lecture** : Depuis MongoDB.
*   **Transformation** :
    *   AgrÃ©gation par `RÃ©gion`, `FiliÃ¨re` et `Date/Heure`.
    *   Calcul des moyennes de consommation et Ã©changes physiques.
    *   Ajout d'un horodatage de traitement (`processed_at`).
*   **Ecriture** : Dans PostgreSQL (Table `regional_energy_stats`), en mode **Append** (ajout sans Ã©craser l'historique).

## ğŸ“ˆ Monitoring
*   **Grafana** : Un dashboard "PostgreSQL Overview" est prÃ©-chargÃ© pour surveiller la santÃ© de la base de donnÃ©es (TPS, Taille, Connexions).
*   **Logs** : Les logs Postgres sont collectÃ©s par Promtail et visibles dans Grafana (Explore -> Loki).

## ğŸ™â€â™‚ï¸ Groupes

* Maxence Tourniayre (Xamez)
* Thomas Nalix 
* Rohart Yoann